from constants import INSTRUCTION_MODEL

# llm = LlamaCPP(
#     model_path=MODEL_PATH,
#     temperature=0.1,
#     max_new_tokens=256,
#     context_window=3000,
#     generate_kwargs={},
#     model_kwargs={"n_gpu_layers": 30},
#     messages_to_prompt=messages_to_prompt,
#     completion_to_prompt=completion_to_prompt,
#     verbose=False,
# )
