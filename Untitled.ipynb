{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1260d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/starscream/.cache/huggingface/datasets/Whispering-GPT___parquet/Whispering-GPT--lex-fridman-podcast-f9b59d9d94797791/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|███████████████████████████████████████████████| 1/1 [00:00<00:00, 399.72it/s]\n",
      "Loading cached processed dataset at /home/starscream/.cache/huggingface/datasets/Whispering-GPT___parquet/Whispering-GPT--lex-fridman-podcast-f9b59d9d94797791/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-aad5ef54e8d74c4d.arrow\n",
      "num_proc must be <= 3. Reducing num_proc to 3 for dataset of size 3.\n",
      "Loading cached processed dataset at /home/starscream/.cache/huggingface/datasets/Whispering-GPT___parquet/Whispering-GPT--lex-fridman-podcast-f9b59d9d94797791/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-fe132911464cec1a_*_of_00003.arrow\n",
      "num_proc must be <= 3. Reducing num_proc to 3 for dataset of size 3.\n",
      "Loading cached processed dataset at /home/starscream/.cache/huggingface/datasets/Whispering-GPT___parquet/Whispering-GPT--lex-fridman-podcast-f9b59d9d94797791/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-473c13efe6acf029_*_of_00003.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'channel', 'channel_id', 'title', 'categories', 'tags', 'description', 'text', 'segments'],\n",
      "    num_rows: 346\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'channel', 'channel_id', 'title', 'categories', 'tags', 'description', 'text', 'segments'],\n",
      "    num_rows: 3\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>channel</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRdL6ZzWBS0</td>\n",
       "      <td>Lex Fridman</td>\n",
       "      <td>UCSHZKyawb77ixDdsGog4iWA</td>\n",
       "      <td>Jed Buchwald: Isaac Newton and the Philosophy ...</td>\n",
       "      <td>[Science &amp; Technology]</td>\n",
       "      <td>[agi, ai, ai podcast, artificial intelligence,...</td>\n",
       "      <td>Jed Buchwald is a historian and philosopher of...</td>\n",
       "      <td>The following is a conversation with Jed Buck...</td>\n",
       "      <td>[{'start': 0.0, 'end': 7.68, 'text': ' The fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TPXTmVdlyoc</td>\n",
       "      <td>Lex Fridman</td>\n",
       "      <td>UCSHZKyawb77ixDdsGog4iWA</td>\n",
       "      <td>Sergey Nazarov: Chainlink, Smart Contracts, an...</td>\n",
       "      <td>[Science &amp; Technology]</td>\n",
       "      <td>[agi, ai, ai podcast, artificial intelligence,...</td>\n",
       "      <td>Sergey Nazarov is the Co-Founder of Chainlink,...</td>\n",
       "      <td>The following is a conversation with Sergey N...</td>\n",
       "      <td>[{'start': 0.0, 'end': 6.5, 'text': ' The foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-t1_ffaFXao</td>\n",
       "      <td>Lex Fridman</td>\n",
       "      <td>UCSHZKyawb77ixDdsGog4iWA</td>\n",
       "      <td>Stephen Wolfram: Fundamental Theory of Physics...</td>\n",
       "      <td>[Science &amp; Technology]</td>\n",
       "      <td>[stephen wolfram, artificial intelligence, agi...</td>\n",
       "      <td>Stephen Wolfram is a computer scientist, mathe...</td>\n",
       "      <td>The following is a conversation with Stephen ...</td>\n",
       "      <td>[{'start': 0.0, 'end': 4.48, 'text': ' The fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCdV6BMMpOo</td>\n",
       "      <td>Lex Fridman</td>\n",
       "      <td>UCSHZKyawb77ixDdsGog4iWA</td>\n",
       "      <td>Philip Goff: Consciousness, Panpsychism, and t...</td>\n",
       "      <td>[Science &amp; Technology]</td>\n",
       "      <td>[agi, ai, ai podcast, artificial intelligence,...</td>\n",
       "      <td>Philip Goff is a philosopher of mind and consc...</td>\n",
       "      <td>I believe our official scientific worldview i...</td>\n",
       "      <td>[{'start': 0.0, 'end': 5.2, 'text': ' I believ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kedt2or9xlo</td>\n",
       "      <td>Lex Fridman</td>\n",
       "      <td>UCSHZKyawb77ixDdsGog4iWA</td>\n",
       "      <td>Oriol Vinyals: DeepMind AlphaStar, StarCraft, ...</td>\n",
       "      <td>[Science &amp; Technology]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>The following is a conversation with Ariol Vi...</td>\n",
       "      <td>[{'start': 0.0, 'end': 3.2800000000000002, 'te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id      channel                channel_id  \\\n",
       "0  TRdL6ZzWBS0  Lex Fridman  UCSHZKyawb77ixDdsGog4iWA   \n",
       "1  TPXTmVdlyoc  Lex Fridman  UCSHZKyawb77ixDdsGog4iWA   \n",
       "2  -t1_ffaFXao  Lex Fridman  UCSHZKyawb77ixDdsGog4iWA   \n",
       "3  BCdV6BMMpOo  Lex Fridman  UCSHZKyawb77ixDdsGog4iWA   \n",
       "4  Kedt2or9xlo  Lex Fridman  UCSHZKyawb77ixDdsGog4iWA   \n",
       "\n",
       "                                               title              categories  \\\n",
       "0  Jed Buchwald: Isaac Newton and the Philosophy ...  [Science & Technology]   \n",
       "1  Sergey Nazarov: Chainlink, Smart Contracts, an...  [Science & Technology]   \n",
       "2  Stephen Wolfram: Fundamental Theory of Physics...  [Science & Technology]   \n",
       "3  Philip Goff: Consciousness, Panpsychism, and t...  [Science & Technology]   \n",
       "4  Oriol Vinyals: DeepMind AlphaStar, StarCraft, ...  [Science & Technology]   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [agi, ai, ai podcast, artificial intelligence,...   \n",
       "1  [agi, ai, ai podcast, artificial intelligence,...   \n",
       "2  [stephen wolfram, artificial intelligence, agi...   \n",
       "3  [agi, ai, ai podcast, artificial intelligence,...   \n",
       "4                                                 []   \n",
       "\n",
       "                                         description  \\\n",
       "0  Jed Buchwald is a historian and philosopher of...   \n",
       "1  Sergey Nazarov is the Co-Founder of Chainlink,...   \n",
       "2  Stephen Wolfram is a computer scientist, mathe...   \n",
       "3  Philip Goff is a philosopher of mind and consc...   \n",
       "4                                                      \n",
       "\n",
       "                                                text  \\\n",
       "0   The following is a conversation with Jed Buck...   \n",
       "1   The following is a conversation with Sergey N...   \n",
       "2   The following is a conversation with Stephen ...   \n",
       "3   I believe our official scientific worldview i...   \n",
       "4   The following is a conversation with Ariol Vi...   \n",
       "\n",
       "                                            segments  \n",
       "0  [{'start': 0.0, 'end': 7.68, 'text': ' The fol...  \n",
       "1  [{'start': 0.0, 'end': 6.5, 'text': ' The foll...  \n",
       "2  [{'start': 0.0, 'end': 4.48, 'text': ' The fol...  \n",
       "3  [{'start': 0.0, 'end': 5.2, 'text': ' I believ...  \n",
       "4  [{'start': 0.0, 'end': 3.2800000000000002, 'te...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import comet_ml\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "COMET_API_KEY = os.getenv(\"COMET_API_KEY\")\n",
    "# experiment = comet_ml.Experiment(\n",
    "#     api_key=COMET_API_KEY,\n",
    "#     project_name=\"clm\",\n",
    "#     log_code=True,\n",
    "#     auto_metric_logging=True,\n",
    "#     auto_param_logging=True,\n",
    "#     auto_histogram_weight_logging=True,\n",
    "#     auto_histogram_gradient_logging=True,\n",
    "#     auto_histogram_activation_logging=True,\n",
    "# )\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    from transformers import GPT2Tokenizer\n",
    "\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(params[\"model\"])\n",
    "    return tokenizer(examples[\"text\"])\n",
    "\n",
    "\n",
    "def group_texts(dat, block_size = 64):\n",
    "    # function from HF script used to chunk data into block_size\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(dat[k], []) for k in dat.keys()}\n",
    "    total_length = len(concatenated_examples[list(dat.keys())[0]])\n",
    "    # We drop the small remainder, though you could add padding instead if the model supports it\n",
    "    # In this, as in all things, we advise you to follow your heart\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoConfig, TFAutoModelForCausalLM\n",
    "from transformers import AdamWeightDecay\n",
    "from transformers import DefaultDataCollator\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"model\": \"gpt2\",\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"weight_decay\": 0.01,\n",
    "}\n",
    "model_checkpoint = params[\"model\"]\n",
    "tokenizer_checkpoint = params[\"model\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint)\n",
    "# experiment.log_parameters(params)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(params[\"model\"])\n",
    "\n",
    "dataset = load_dataset(\"Whispering-GPT/lex-fridman-podcast\")\n",
    "filtered_dataset = dataset.filter(lambda x: \"deepmind\" in x[\"title\"].lower())\n",
    "\n",
    "print(dataset[\"train\"])\n",
    "print(filtered_dataset[\"train\"])\n",
    "\n",
    "tokenized_datasets = filtered_dataset.map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    num_proc=4, \n",
    "    remove_columns = ['id', 'channel', 'channel_id', 'title', 'categories', 'tags', 'description', 'text', 'segments'])\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")\n",
    "\n",
    "df_test = pd.DataFrame( dataset['train'] )\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba97cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 13:14:48.561229: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1080]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-02 13:14:48.561508: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1080]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-02 13:14:50.382235: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\n",
      "2023-04-02 13:14:50.448887: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\n",
      "2023-04-02 13:14:50.466463: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\n",
      "2023-04-02 13:14:54.272831: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\n",
      "2023-04-02 13:14:54.373715: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/34 [==>...........................] - ETA: 7:16 - loss: 10.5472"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "gpt2 = TFAutoModelForCausalLM.from_config(config)\n",
    "learning_rate = params['learning_rate']\n",
    "weight_decay = params['weight_decay']\n",
    "\n",
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
    "gpt2.compile(optimizer=optimizer)\n",
    "\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "train_set = lm_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=params['batch_size'],\n",
    "    collate_fn=data_collator,)\n",
    "\n",
    "gpt2.fit(train_set, epochs=params['epochs'])\n",
    "eval_loss = gpt2.evaluate(train_set)\n",
    "experiment.log_metrics({\"eval_loss\":eval_loss})\n",
    "print(f\"Perplexity: {math.exp(eval_loss):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e53615ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lex podcast                        276\n",
       "agi                                275\n",
       "lex ai                             275\n",
       "mit ai                             275\n",
       "lex mit                            275\n",
       "lex fridman                        275\n",
       "lex jre                            275\n",
       "artificial intelligence            275\n",
       "artificial intelligence podcast    275\n",
       "ai podcast                         275\n",
       "ai                                 275\n",
       "physics                             12\n",
       "deep learning                       12\n",
       "elon musk                           11\n",
       "russia                              10\n",
       "consciousness                       10\n",
       "bitcoin                              9\n",
       "stanford                             9\n",
       "twitter                              8\n",
       "aliens                               7\n",
       "ukraine                              7\n",
       "machine learning                     7\n",
       "war                                  7\n",
       "putin                                6\n",
       "space                                6\n",
       "mit                                  6\n",
       "robotics                             6\n",
       "economics                            5\n",
       "eric weinstein                       5\n",
       "programming                          5\n",
       "robots                               5\n",
       "meditation                           5\n",
       "joe rogan                            5\n",
       "social media                         5\n",
       "communism                            5\n",
       "science                              5\n",
       "ufo                                  5\n",
       "quantum mechanics                    5\n",
       "philosophy                           5\n",
       "cryptocurrency                       5\n",
       "religion                             5\n",
       "crypto                               5\n",
       "psychology                           5\n",
       "bjj                                  4\n",
       "government                           4\n",
       "manolis kellis                       4\n",
       "evolution                            4\n",
       "hitler                               4\n",
       "judo                                 4\n",
       "covid                                4\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = df_test.copy()[['id', 'tags']]\n",
    "_= _.explode('tags')\n",
    "_.tags.value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcdfab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = [\"agi\", \"ai\", \"intelligence\", \"learning\", \"consciousness\", \"robotics\", \"psychology\", \"evolution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47007b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promotheus",
   "language": "python",
   "name": "promotheus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
